{
  "defaultAiPlatform": "chatgpt",
  "aiPlatforms": {
    "claude": {
      "name": "Claude",
      "url": "https://claude.ai/new",
      "icon": "images/claude_logo.png",
      "docLink": "https://docs.anthropic.com/claude/reference/getting-started-with-the-api",
      "modelApiLink": "https://console.anthropic.com/models",
      "consoleApiLink": "https://console.anthropic.com/",
      "api": {
        "endpoint": "https://api.anthropic.com/v1/messages",
        "models": [
          {
            "id": "claude-3-7-sonnet-latest",
            "maxTokens": 4000,
            "temperature": 0.7,
            "parameterStyle": "standard",
            "contextWindow": 200000,
            "inputTokenPrice": 3.00,
            "outputTokenPrice": 15.00,
            "supportsTemperature": true,
            "supportsTopP": true
          },
          {
            "id": "claude-3-5-haiku-latest",
            "maxTokens": 4000,
            "temperature": 0.7,
            "parameterStyle": "standard",
            "contextWindow": 200000,
            "inputTokenPrice": 0.25,
            "outputTokenPrice": 1.25,
            "supportsTemperature": true,
            "supportsTopP": true
          },
          {
            "id": "claude-3-5-sonnet-latest",
            "maxTokens": 4000,
            "temperature": 0.7,
            "parameterStyle": "standard",
            "contextWindow": 200000,
            "inputTokenPrice": 3.00,
            "outputTokenPrice": 15.00,
            "supportsTemperature": true,
            "supportsTopP": true
          },
          {
            "id": "claude-3-opus-latest",
            "maxTokens": 4000,
            "temperature": 0.7,
            "parameterStyle": "standard",
            "contextWindow": 200000,
            "inputTokenPrice": 15.00,
            "outputTokenPrice": 75.00,
            "supportsTemperature": true,
            "supportsTopP": true
          }
        ],
        "defaultModel": "claude-3-7-sonnet-latest",
        "requiresModel": true,
        "authType": "header",
        "authHeaderName": "x-api-key"
      }
    },
    "chatgpt": {
      "name": "ChatGPT",
      "url": "https://chatgpt.com/",
      "icon": "images/chatgpt_logo.png",
      "docLink": "https://platform.openai.com/docs/api-reference",
      "modelApiLink": "https://platform.openai.com/models",
      "consoleApiLink": "https://platform.openai.com/",
      "api": {
        "endpoint": "https://api.openai.com/v1/chat/completions",
        "models": [
          {
            "id": "gpt-4.5-preview",
            "maxTokens": 16384,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 128000,
            "inputTokenPrice": 75,
            "outputTokenPrice": 150,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "gpt-4o",
            "maxTokens": 16384,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 128000,
            "inputTokenPrice": 5.00,
            "outputTokenPrice": 15.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "gpt-4o-mini",
            "maxTokens": 16384,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 128000,
            "inputTokenPrice": 1.10,
            "outputTokenPrice": 4.40,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "o1",
            "maxTokens": 200000,
            "parameterStyle": "reasoning",
            "tokenParameter": "max_completion_tokens",
            "contextWindow": 128000,
            "inputTokenPrice": 15.00,
            "outputTokenPrice": 60.00,
            "supportsTemperature": false,
            "supportsTopP": false
          },
          {
            "id": "o3-mini",
            "maxTokens": 100000,
            "parameterStyle": "reasoning",
            "tokenParameter": "max_completion_tokens",
            "contextWindow": 200000,
            "inputTokenPrice": 1.10,
            "outputTokenPrice": 4.40,
            "supportsTemperature": false,
            "supportsTopP": false
          },
          {
            "id": "o1-mini",
            "maxTokens": 65536,
            "parameterStyle": "reasoning",
            "tokenParameter": "max_completion_tokens",
            "contextWindow": 128000,
            "inputTokenPrice": 1.10,
            "outputTokenPrice": 4.40,
            "supportsTemperature": false,
            "supportsTopP": false
          },
          {
            "id": "gpt-3.5-turbo",
            "maxTokens": 4096,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 16385,
            "inputTokenPrice": 0.50,
            "outputTokenPrice": 1.50,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          }
        ],
        "defaultModel": "gpt-4o",
        "requiresModel": true,
        "authType": "bearer",
        "authHeaderName": "Authorization"
      }
    },
    "deepseek": {
      "name": "DeepSeek",
      "url": "https://chat.deepseek.com/",
      "icon": "images/deepseek_logo.png",
      "docLink": "https://platform.deepseek.ai/docs",
      "modelApiLink": "https://platform.deepseek.com/models",
      "consoleApiLink": "https://platform.deepseek.com/",
      "api": {
        "endpoint": "https://api.deepseek.com/v1/chat/completions",
        "models": [
          {
            "id": "deepseek-chat",
            "maxTokens": 4000,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 32768,
            "inputTokenPrice": 0.14,
            "outputTokenPrice": 0.28,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "deepseek-reasoner",
            "maxTokens": 4000,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 32768,
            "inputTokenPrice": 0.28,
            "outputTokenPrice": 0.56,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          }
        ],
        "defaultModel": "deepseek-chat",
        "requiresModel": true,
        "authType": "bearer",
        "authHeaderName": "Authorization"
      }
    },
    "mistral": {
      "name": "Mistral",
      "url": "https://chat.mistral.ai/chat",
      "icon": "images/mistral_logo.png",
      "docLink": "https://docs.mistral.ai/api/",
      "consoleApiLink": "https://console.mistral.ai/",
      "api": {
        "endpoint": "https://api.mistral.ai/v1/chat/completions",
        "models": [
          {
            "id": "codestral-latest",
            "maxTokens": 4096,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 32768,
            "inputTokenPrice": 0.20,
            "outputTokenPrice": 0.20,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "mistral-large-latest",
            "maxTokens": 4096,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 32768,
            "inputTokenPrice": 8.00,
            "outputTokenPrice": 24.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "pixtral-large-latest",
            "maxTokens": 4096,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 32768,
            "inputTokenPrice": 2.70,
            "outputTokenPrice": 8.10,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "mistral-saba-latest",
            "maxTokens": 4096,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 32768,
            "inputTokenPrice": 2.00,
            "outputTokenPrice": 6.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "ministral-3b-latest",
            "maxTokens": 4096,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 32768,
            "inputTokenPrice": 2.00,
            "outputTokenPrice": 6.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "ministral-8b-latest",
            "maxTokens": 4096,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 32768,
            "inputTokenPrice": 2.00,
            "outputTokenPrice": 6.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          }
        ],
        "defaultModel": "mistral-large-latest",
        "requiresModel": true,
        "authType": "bearer",
        "authHeaderName": "Authorization"
      }
    },
    "gemini": {
      "name": "Gemini",
      "url": "https://gemini.google.com/",
      "icon": "images/gemini_logo.png",
      "docLink": "https://ai.google.dev/docs",
      "modelApiLink": "https://console.cloud.google.com/ai/gemini/models",
      "consoleApiLink": "https://ai.google.dev/",
      "api": {
        "endpoint": "https://generativelanguage.googleapis.com/v1/models/{model}:generateContent",
        "models": [
          {
            "id": "gemini-2.0-flash",
            "maxTokens": 8192,
            "temperature": 0.7,
            "topP": 0.95,
            "parameterStyle": "standard",
            "contextWindow": 1048576,
            "inputTokenPrice": 0.35,
            "outputTokenPrice": 1.05,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "maxOutputTokens"
          },
          {
            "id": "gemini-2.0-flash-lite",
            "maxTokens": 8192,
            "temperature": 0.7,
            "topP": 0.95,
            "parameterStyle": "standard",
            "contextWindow": 1048576,
            "inputTokenPrice": 0.35,
            "outputTokenPrice": 1.05,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "maxOutputTokens"
          },
          {
            "id": "gemini-1.5-flash",
            "maxTokens": 8192,
            "temperature": 0.7,
            "topP": 0.95,
            "parameterStyle": "standard",
            "contextWindow": 1048576,
            "inputTokenPrice": 0.35,
            "outputTokenPrice": 1.05,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "maxOutputTokens"
          },
          {
            "id": "gemini-1.5-flash-8b",
            "maxTokens": 8192,
            "temperature": 0.7,
            "topP": 0.95,
            "parameterStyle": "standard",
            "contextWindow": 1048576,
            "inputTokenPrice": 0.35,
            "outputTokenPrice": 1.05,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "maxOutputTokens"
          },
          {
            "id": "gemini-1.5-pro",
            "maxTokens": 8192,
            "temperature": 0.7,
            "topP": 0.95,
            "parameterStyle": "standard",
            "contextWindow": 2097152,
            "inputTokenPrice": 7.00,
            "outputTokenPrice": 21.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "maxOutputTokens"
          }
        ],
        "defaultModel": "gemini-2.0-flash",
        "requiresModel": true,
        "authType": "query",
        "authParamName": "key"
      }
    },
    "grok": {
      "name": "Grok",
      "url": "https://grok.com/",
      "icon": "images/grok_logo.png",
      "docLink": "https://x.ai/api-docs",
      "modelApiLink": "https://console.x.ai/models",
      "consoleApiLink": "https://console.x.ai/",
      "api": {
        "endpoint": "https://api.x.ai/v1/chat/completions",
        "models": [
          {
            "id": "grok-beta",
            "maxTokens": 4000,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 128000,
            "inputTokenPrice": 0.00,
            "outputTokenPrice": 0.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "grok-vision-beta",
            "maxTokens": 4000,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 128000,
            "inputTokenPrice": 0.00,
            "outputTokenPrice": 0.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "grok-2-1212",
            "maxTokens": 4000,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 128000,
            "inputTokenPrice": 0.00,
            "outputTokenPrice": 0.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          },
          {
            "id": "grok-2-vision-1212",
            "maxTokens": 4000,
            "temperature": 0.7,
            "topP": 1.0,
            "parameterStyle": "standard",
            "contextWindow": 128000,
            "inputTokenPrice": 0.00,
            "outputTokenPrice": 0.00,
            "supportsTemperature": true,
            "supportsTopP": true,
            "tokenParameter": "max_tokens"
          }
        ],
        "defaultModel": "grok-2-1212",
        "requiresModel": true,
        "authType": "bearer",
        "authHeaderName": "Authorization"
      }
    }
  }
}